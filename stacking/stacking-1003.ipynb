{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法说明\n",
    "1） 在原始特殊的基础上增加，每个grid以及每个grid每小时的最大值、最小值、标准差、偏度、峰度等统计值  \n",
    "2） 使用lightgbm、RandomForestRegressor、XGBRegressor、Ridge、LinearRegression、BaggingRegressor、GradientBoostingRegressor 7个模型，对所有数据分别训练、预测，将预测结果以及这些结果的差值作为新增的特征加到数据集中；  \n",
    "3） 再用lgb、xgb做训练、预测；  \n",
    "4） 融合lgb、xgb的预测结果做最后结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_SEED = 42\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "random.seed(RANDOM_SEED)\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../huan/pr_qf_feature_v3/PR_QF_BOT_all_data_feature_sum_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "all_data['weather'] = le.fit_transform(all_data['weather'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data.holiday_counter > 0, 'holiday_counter'] = all_data.loc[all_data.holiday_counter > 0, 'holiday_counter'] \\\n",
    "                                                                            / all_data.loc[all_data.holiday_counter > 0, 'holiday_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data.school_holiday_counter > 0, 'school_holiday_counter'] = all_data.loc[all_data.school_holiday_counter > 0, 'school_holiday_counter'] \\\n",
    "                                                                                            / all_data.loc[all_data.school_holiday_counter > 0, 'school_holiday_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "feature_standard_scaler_col = ['temperature','humidity',\\\n",
    "                               'wind_speed',\\\n",
    "                               'holiday_days','school_holiday_days','dew_point','pressure']\n",
    "all_data[feature_standard_scaler_col] = scaler.fit_transform(all_data[feature_standard_scaler_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data[all_data.ymd < '2017-03-13']\n",
    "test_data = all_data[all_data.ymd >= '2017-03-13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_data = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_max(grid,hour):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    grid = grid[grid[\"hour\"]==hour]\n",
    "    return grid[\"y\"].max()\n",
    "def add_min(grid,hour):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    grid = grid[grid[\"hour\"]==hour]\n",
    "    return grid[\"y\"].min()\n",
    "def add_std(grid,hour):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    grid = grid[grid[\"hour\"]==hour]\n",
    "    return grid[\"y\"].std()\n",
    "def add_mean(grid,hour):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    grid = grid[grid[\"hour\"]==hour]\n",
    "    return grid[\"y\"].mean()\n",
    "def add_kurt(grid,hour):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    grid = grid[grid[\"hour\"]==hour]\n",
    "    return grid[\"y\"].kurt()\n",
    "\n",
    "def add_skew(grid,hour):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    grid = grid[grid[\"hour\"]==hour]\n",
    "    return grid[\"y\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_max_2(grid):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "\n",
    "    return grid[\"y\"].max()\n",
    "def add_min_2(grid):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    return grid[\"y\"].min()\n",
    "def add_std_2(grid):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    return grid[\"y\"].std()\n",
    "def add_mean_2(grid):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    return grid[\"y\"].mean()\n",
    "\n",
    "def add_kurt_2(grid):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    return grid[\"y\"].kurt()\n",
    "\n",
    "def add_skew_2(grid):\n",
    "    grid = train_all_data[train_all_data[\"grid_id\"]==grid]\n",
    "    return grid[\"y\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"add_max\"] = all_data.apply(lambda row: add_max(row['grid_id'], row['hour']), axis=1)\n",
    "all_data[\"add_min\"] = all_data.apply(lambda row: add_min(row['grid_id'], row['hour']), axis=1)\n",
    "\n",
    "all_data[\"add_std\"] = all_data.apply(lambda row: add_std(row['grid_id'], row['hour']), axis=1)\n",
    "all_data[\"add_mean\"] = all_data.apply(lambda row: add_mean(row['grid_id'], row['hour']), axis=1)\n",
    "\n",
    "all_data[\"add_kurt\"] = all_data.apply(lambda row: add_kurt(row['grid_id'], row['hour']), axis=1)\n",
    "all_data[\"add_skew\"] = all_data.apply(lambda row: add_skew(row['grid_id'], row['hour']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"add_max_2\"] = all_data.apply(lambda row: add_max_2(row['grid_id']), axis=1)\n",
    "all_data[\"add_min_2\"] = all_data.apply(lambda row: add_min_2(row['grid_id']), axis=1)\n",
    "\n",
    "all_data[\"add_std_2\"] = all_data.apply(lambda row: add_std_2(row['grid_id']), axis=1)\n",
    "all_data[\"add_mean_2\"] = all_data.apply(lambda row: add_mean_2(row['grid_id']), axis=1)\n",
    "\n",
    "all_data[\"add_kurt_2\"] = all_data.apply(lambda row: add_kurt_2(row['grid_id']), axis=1)\n",
    "all_data[\"add_skew_2\"] = all_data.apply(lambda row: add_skew_2(row['grid_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data[all_data.ymd < '2017-03-13']\n",
    "test_data = all_data[all_data.ymd >= '2017-03-13']\n",
    "train_all_data = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_col = ['weekday','grid_id','hour','weather','holiday','holiday_bf_af','school_holiday','school_holiday_bf_af']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2 = all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>ymd</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>holiday</th>\n",
       "      <th>holiday_counter</th>\n",
       "      <th>holiday_days</th>\n",
       "      <th>holiday_bf_af</th>\n",
       "      <th>...</th>\n",
       "      <th>add_std</th>\n",
       "      <th>add_mean</th>\n",
       "      <th>add_kurt</th>\n",
       "      <th>add_skew</th>\n",
       "      <th>add_max_2</th>\n",
       "      <th>add_min_2</th>\n",
       "      <th>add_std_2</th>\n",
       "      <th>add_mean_2</th>\n",
       "      <th>add_kurt_2</th>\n",
       "      <th>add_skew_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.515168</td>\n",
       "      <td>19.957143</td>\n",
       "      <td>0.148984</td>\n",
       "      <td>0.692111</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.707762</td>\n",
       "      <td>12.714286</td>\n",
       "      <td>-0.589486</td>\n",
       "      <td>0.192291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.057779</td>\n",
       "      <td>19.357143</td>\n",
       "      <td>0.460322</td>\n",
       "      <td>0.433468</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.707762</td>\n",
       "      <td>12.714286</td>\n",
       "      <td>-0.589486</td>\n",
       "      <td>0.192291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.244656</td>\n",
       "      <td>18.171429</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>-0.079883</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.707762</td>\n",
       "      <td>12.714286</td>\n",
       "      <td>-0.589486</td>\n",
       "      <td>0.192291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.903542</td>\n",
       "      <td>17.314286</td>\n",
       "      <td>-0.408345</td>\n",
       "      <td>-0.063325</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.707762</td>\n",
       "      <td>12.714286</td>\n",
       "      <td>-0.589486</td>\n",
       "      <td>0.192291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.376604</td>\n",
       "      <td>17.071429</td>\n",
       "      <td>0.028195</td>\n",
       "      <td>0.281969</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.707762</td>\n",
       "      <td>12.714286</td>\n",
       "      <td>-0.589486</td>\n",
       "      <td>0.192291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_id         ymd  weekday  month  day  hour  holiday  holiday_counter  \\\n",
       "0        1  2017-01-02        0      1    2     9        1              1.0   \n",
       "1        1  2017-01-02        0      1    2    10        1              1.0   \n",
       "2        1  2017-01-02        0      1    2    11        1              1.0   \n",
       "3        1  2017-01-02        0      1    2    12        1              1.0   \n",
       "4        1  2017-01-02        0      1    2    13        1              1.0   \n",
       "\n",
       "   holiday_days  holiday_bf_af     ...       add_std   add_mean  add_kurt  \\\n",
       "0      0.428571              0     ...      6.515168  19.957143  0.148984   \n",
       "1      0.428571              0     ...      6.057779  19.357143  0.460322   \n",
       "2      0.428571              0     ...      5.244656  18.171429  0.002011   \n",
       "3      0.428571              0     ...      4.903542  17.314286 -0.408345   \n",
       "4      0.428571              0     ...      5.376604  17.071429  0.028195   \n",
       "\n",
       "   add_skew  add_max_2  add_min_2  add_std_2  add_mean_2  add_kurt_2  \\\n",
       "0  0.692111       40.0        0.0   7.707762   12.714286   -0.589486   \n",
       "1  0.433468       40.0        0.0   7.707762   12.714286   -0.589486   \n",
       "2 -0.079883       40.0        0.0   7.707762   12.714286   -0.589486   \n",
       "3 -0.063325       40.0        0.0   7.707762   12.714286   -0.589486   \n",
       "4  0.281969       40.0        0.0   7.707762   12.714286   -0.589486   \n",
       "\n",
       "   add_skew_2  \n",
       "0    0.192291  \n",
       "1    0.192291  \n",
       "2    0.192291  \n",
       "3    0.192291  \n",
       "4    0.192291  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2 = pd.get_dummies(all_data2, columns=categorical_feature_col,drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if 'grid_id_1' in all_data2.columns.tolist():\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = all_data2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in [\"ymd\",\"month\",\"day\",\"y\"]:\n",
    "    col.remove(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "minScaler = MinMaxScaler()\n",
    "all_data2[col] = minScaler.fit_transform(all_data2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data2[all_data.ymd < '2017-03-13']\n",
    "test_data = all_data2[all_data.ymd >= '2017-03-13']\n",
    "train_all_data = all_data2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_data = train_data[train_data.ymd >= '2017-02-27']\n",
    "train_data = train_data[train_data.ymd < '2017-02-27']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用lightGBm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = train_data['y'].values\n",
    "train_x = train_data[col]\n",
    "\n",
    "lgb_params = {\n",
    "    'task': 'train',\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': \"mse\",\n",
    "    'metric': 'l2',\n",
    "    'learning_rate': 0.01,\n",
    "    'verbose': 0,\n",
    "    'bagging_seed': RANDOM_SEED,\n",
    "    'num_boost_round': 1500,\n",
    " }\n",
    "dtrain = lgb.Dataset(train_x, train_Y)\n",
    "model = lgb.train(lgb_params, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2[\"pre_lgb\"] = model.predict(all_data2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1500,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=1500)\n",
    "xgb_model.fit(train_x,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2[\"pre_xgb\"] = xgb_model.predict(all_data2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=1000,criterion='mse',random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(train_x,train_Y)\n",
    "all_data2[\"pre_rf\"] = rf.predict(all_data2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_Y)\n",
    "all_data2[\"pre_lr\"] = lr.predict(all_data2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = Ridge()\n",
    "rg.fit(train_x, train_Y)\n",
    "all_data2[\"pre_rg\"] = rg.predict(all_data2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgr = BaggingRegressor(n_estimators=750, random_state=RANDOM_SEED)\n",
    "bgr.fit(train_x, train_Y)\n",
    "all_data2[\"pre_bgr\"] = bgr.predict(all_data2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt = GradientBoostingRegressor(n_estimators=750,criterion=\"mse\")\n",
    "gbdt.fit(train_x, train_Y)\n",
    "all_data2[\"pre_gbdt\"] = gbdt.predict(all_data2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2.to_csv(\"./feature_all_data2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2 = [\"pre_gbdt\",\"pre_bgr\",\"pre_rg\",\"pre_lr\",\"pre_rf\",\"pre_xgb\",\"pre_lgb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fc2两两求差值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_feature(feature1, feature2):\n",
    "    if feature1==feature2: \n",
    "        return \n",
    "    \n",
    "    sub_feature=\"{}_sub_{}\".format(feature1, feature2)\n",
    "    print(sub_feature)\n",
    "    all_data2[sub_feature]=all_data2[feature1]-all_data2[feature2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_gbdt_sub_pre_bgr\n",
      "pre_gbdt_sub_pre_rg\n",
      "pre_gbdt_sub_pre_lr\n",
      "pre_gbdt_sub_pre_rf\n",
      "pre_gbdt_sub_pre_xgb\n",
      "pre_gbdt_sub_pre_lgb\n",
      "pre_bgr_sub_pre_rg\n",
      "pre_bgr_sub_pre_lr\n",
      "pre_bgr_sub_pre_rf\n",
      "pre_bgr_sub_pre_xgb\n",
      "pre_bgr_sub_pre_lgb\n",
      "pre_rg_sub_pre_lr\n",
      "pre_rg_sub_pre_rf\n",
      "pre_rg_sub_pre_xgb\n",
      "pre_rg_sub_pre_lgb\n",
      "pre_lr_sub_pre_rf\n",
      "pre_lr_sub_pre_xgb\n",
      "pre_lr_sub_pre_lgb\n",
      "pre_rf_sub_pre_xgb\n",
      "pre_rf_sub_pre_lgb\n",
      "pre_xgb_sub_pre_lgb\n"
     ]
    }
   ],
   "source": [
    "for index1, feature1 in enumerate(fc2):\n",
    "    for index2, feature2 in enumerate(fc2[index1+1:]):\n",
    "        get_sub_feature(feature1, feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2.to_csv(\"./feature_all_data2_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = all_data2.columns.tolist()\n",
    "for ii in [\"ymd\",\"month\",\"day\",\"y\"]:\n",
    "    fc.remove(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data2[all_data2.ymd < '2017-03-13']\n",
    "test_data = all_data2[all_data2.ymd >= '2017-03-13']\n",
    "train_all_data = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 暂时没用多项式特征\n",
    "#from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "poly = PolynomialFeatures()\n",
    "poly.fit(train_all_data[fc2])\n",
    "train_ploy = poly.transform(train_all_data[fc2])\n",
    "train_ploy = pd.DataFrame(train_ploy, columns=poly.get_feature_names())\n",
    "X_test_poly = poly.transform(test_data[fc2])\n",
    "X_test_poly = pd.DataFrame(X_test_poly, columns=poly.get_feature_names())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_poly.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.reset_index(inplace=True)\n",
    "#train_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = pd.concat([test_data,X_test_poly],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ploy = pd.concat([train_data,train_ploy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc = train_ploy.columns.tolist()\n",
    "#for ii in [\"ymd\",\"month\",\"day\",\"y\"]:\n",
    "#    fc.remove(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x = train_ploy[fc]\n",
    "#train_y = train_ploy[\"y\"]\n",
    "#test_x = test_data[fc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_all_data['y'].values\n",
    "train_x = train_all_data[fc]\n",
    "test_x = test_data[fc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(GradientBoostingRegressor(random_state=RANDOM_SEED))\n",
    "X_train = sfm.fit_transform(train_x, train_y)\n",
    "X_test = sfm.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49000, 23), (49000, 137))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9800, 23), (9800, 137))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape,test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor(boosting_type=\"gbdt\",n_estimators=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=900, n_jobs=-1, num_leaves=31, objective=None,\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lgb_model.fit(X_train,train_y)  #选择特征后的训练数据\n",
    "lgb_model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线下验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modele: LGB RMSE : 0.4907682905687564\n",
      "modele: LGB RMSE CEIL: 0.774109099519689\n",
      "modele: LGB RMSE round: 0.5480205567423952\n",
      "modele: LGB RMSE floor: 0.7766621412381661\n"
     ]
    }
   ],
   "source": [
    "pre_train = lgb_model.predict(train_x)\n",
    "print (\"modele: LGB RMSE :\",np.sqrt(metrics.mean_squared_error(train_y, pre_train)))\n",
    "print (\"modele: LGB RMSE CEIL:\",np.sqrt(metrics.mean_squared_error(train_y, np.ceil(pre_train))))\n",
    "print (\"modele: LGB RMSE round:\",np.sqrt(metrics.mean_squared_error(train_y, np.round(pre_train))))\n",
    "print (\"modele: LGB RMSE floor:\",np.sqrt(metrics.mean_squared_error(train_y, np.floor(pre_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_importances(importnce_weight, feature_name):\n",
    "    pd_fc_w=pd.DataFrame(data=feature_name, columns=['feature'])\n",
    "    pd_fc_w['weight']=importnce_weight\n",
    "    \n",
    "    result = pd_fc_w.sort_values(by=['weight'],ascending=False)\n",
    "    \n",
    "    return result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pre_bgr_sub_pre_rf</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pre_gbdt_sub_pre_xgb</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pre_rg_sub_pre_lr</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pre_gbdt_sub_pre_lgb</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pre_rf</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  weight\n",
       "0    pre_bgr_sub_pre_rf    1357\n",
       "1  pre_gbdt_sub_pre_xgb    1105\n",
       "2     pre_rg_sub_pre_lr    1048\n",
       "3  pre_gbdt_sub_pre_lgb     900\n",
       "4                pre_rf     889"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_fc_importance=analyze_importances(lgb_model.feature_importances_,fc)\n",
    "lgb_fc_importance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去除特征重要性为0的特征，重跑模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grid_id_7' 'holiday_0' 'grid_id_11' 'grid_id_1' 'grid_id_14'\n",
      " 'grid_id_43' 'grid_id_44' 'grid_id_45' 'school_holiday_1'\n",
      " 'school_holiday_0' 'weather_6' 'holiday_1']\n"
     ]
    }
   ],
   "source": [
    "fc_zero=lgb_fc_importance[lgb_fc_importance['weight']==0]['feature'].values\n",
    "print(fc_zero)\n",
    "\n",
    "fc3=fc.copy()\n",
    "for ii in fc_zero:\n",
    "    fc3.remove(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 125)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fc), len(fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = all_data2[all_data2.ymd >= '2017-03-13']\n",
    "\n",
    "train_y2 = train_all_data['y'].values\n",
    "train_x2 = train_all_data[fc3]\n",
    "test_x2 = test_data[fc3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=750, n_jobs=-1, num_leaves=31, objective=None,\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model2 = lgb.LGBMRegressor(boosting_type=\"gbdt\",n_estimators=750)\n",
    "\n",
    "#lgb_model.fit(X_train,train_y)  #选择特征后的训练数据\n",
    "lgb_model2.fit(train_x2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modele: LGB RMSE : 0.5226635514837483\n",
      "modele: LGB RMSE CEIL: 0.7922842202860573\n",
      "modele: LGB RMSE round: 0.580657614525223\n",
      "modele: LGB RMSE floor: 0.7935196717081153\n"
     ]
    }
   ],
   "source": [
    "pre_train2 = lgb_model2.predict(train_x2)\n",
    "print (\"modele: LGB RMSE :\",np.sqrt(metrics.mean_squared_error(train_y2, pre_train2)))\n",
    "print (\"modele: LGB RMSE CEIL:\",np.sqrt(metrics.mean_squared_error(train_y2, np.ceil(pre_train2))))\n",
    "print (\"modele: LGB RMSE round:\",np.sqrt(metrics.mean_squared_error(train_y2, np.round(pre_train2))))\n",
    "print (\"modele: LGB RMSE floor:\",np.sqrt(metrics.mean_squared_error(train_y2, np.floor(pre_train2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lgb预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model, test_x, lable=\"\",date=20181001):\n",
    "    pre = model.predict(test_x)\n",
    "    test_data = all_data[all_data.ymd >= '2017-03-13'] #重取test_data，为了'grid_id'和'hour'\n",
    "    \n",
    "    test_pred_pd = test_data[['grid_id','ymd','hour']].copy()\n",
    "    test_pred_pd['car_number'] = 0\n",
    "    \n",
    "    test_pred_pd['car_number'] = np.ceil(pre)\n",
    "    test_pred_pd['day'] = pd.to_datetime(test_pred_pd.ymd, format='%Y-%m-%d').dt.strftime('%Y%m%d')\n",
    "    test_pred_pd = test_pred_pd.sort_values(by=['day','hour','grid_id'])\n",
    "    \n",
    "    test_pred_pd[['grid_id','day','hour','car_number']].to_csv('result/{}_result_{}.csv'.format(lable,date),index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict(lgb_model2,test_x2, \"lgb\", 20181004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的代码不运行，整理到上面函数中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pre = lgb_model.predict(X_test) #对应特殊选择后的测试数据\n",
    "pre = lgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_data = all_data[all_data.ymd >= '2017-03-13'] #重取test_data，为了'grid_id'和'hour'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_pred_pd = test_data[['grid_id','ymd','hour']].copy()\n",
    "test_pred_pd['car_number'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_pred_pd['car_number'] = np.ceil(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_pred_pd['day'] = pd.to_datetime(test_pred_pd.ymd, format='%Y-%m-%d').dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_pred_pd = test_pred_pd.sort_values(by=['day','hour','grid_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_pred_pd[['grid_id','day','hour','car_number']].to_csv('result/lgb_result_{0}.csv'.format(20181003),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = test_pred_pd[['grid_id','day','hour','car_number']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(n_estimators=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgb_model.fit(X_train,train_y)\n",
    "xgb_model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modele: LGB RMSE : 0.7116176903431104\n",
      "modele: LGB RMSE CEIL: 0.9215226972965197\n",
      "modele: LGB RMSE round: 0.7609339052527921\n",
      "modele: LGB RMSE floor: 0.9221757767721435\n"
     ]
    }
   ],
   "source": [
    "pre_train = xgb_model.predict(train_x)\n",
    "print (\"modele: LGB RMSE :\",np.sqrt(metrics.mean_squared_error(train_y, pre_train)))\n",
    "print (\"modele: LGB RMSE CEIL:\",np.sqrt(metrics.mean_squared_error(train_y, np.ceil(pre_train))))\n",
    "print (\"modele: LGB RMSE round:\",np.sqrt(metrics.mean_squared_error(train_y, np.round(pre_train))))\n",
    "print (\"modele: LGB RMSE floor:\",np.sqrt(metrics.mean_squared_error(train_y, np.floor(pre_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre = xgb_model.predict(X_test)\n",
    "pre = xgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_pd = test_data[['grid_id','ymd','hour']].copy()\n",
    "test_pred_pd['car_number'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_pd['car_number'] = np.ceil(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_pd['day'] = pd.to_datetime(test_pred_pd.ymd, format='%Y-%m-%d').dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_pd = test_pred_pd.sort_values(by=['day','hour','grid_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_pd[['grid_id','day','hour','car_number']].to_csv('result/xgb_result_{0}.csv'.format(20181003),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = test_pred_pd[['grid_id','day','hour','car_number']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去除0特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fc_importance=analyze_importances(xgb_model.feature_importances_,fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grid_id_45' 'grid_id_2' 'grid_id_1' 'grid_id_44' 'grid_id_43'\n",
      " 'grid_id_37' 'grid_id_30' 'grid_id_33' 'grid_id_5' 'grid_id_29'\n",
      " 'grid_id_26' 'grid_id_23' 'grid_id_22' 'grid_id_21' 'grid_id_4'\n",
      " 'holiday_1' 'holiday_0' 'hour_13' 'weather_6' 'weather_4'\n",
      " 'school_holiday_0' 'school_holiday_1' 'school_holiday_bf_af_1' 'hour_15'\n",
      " 'grid_id_14' 'grid_id_7' 'grid_id_49' 'grid_id_12' 'grid_id_11'\n",
      " 'grid_id_10' 'grid_id_9' 'grid_id_8' 'grid_id_6']\n"
     ]
    }
   ],
   "source": [
    "fc_zero=xgb_fc_importance[xgb_fc_importance['weight']==0]['feature'].values\n",
    "print(fc_zero)\n",
    "\n",
    "fc3=fc.copy()\n",
    "for ii in fc_zero:\n",
    "    fc3.remove(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = all_data2[all_data2.ymd >= '2017-03-13']\n",
    "\n",
    "train_y2 = train_all_data['y'].values\n",
    "train_x2 = train_all_data[fc3]\n",
    "test_x2 = test_data[fc3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=750,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model2 = xgb.XGBRegressor(n_estimators=750)\n",
    "\n",
    "#xgb_model.fit(X_train,train_y)\n",
    "xgb_model2.fit(train_x2,train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modele: LGB RMSE : 0.7249102864721092\n",
      "modele: LGB RMSE CEIL: 0.9319827448696107\n",
      "modele: LGB RMSE round: 0.7732254205730746\n",
      "modele: LGB RMSE floor: 0.9322673698996398\n"
     ]
    }
   ],
   "source": [
    "pre_train2 = xgb_model2.predict(train_x2)\n",
    "print (\"modele: LGB RMSE :\",np.sqrt(metrics.mean_squared_error(train_y2, pre_train2)))\n",
    "print (\"modele: LGB RMSE CEIL:\",np.sqrt(metrics.mean_squared_error(train_y2, np.ceil(pre_train2))))\n",
    "print (\"modele: LGB RMSE round:\",np.sqrt(metrics.mean_squared_error(train_y2, np.round(pre_train2))))\n",
    "print (\"modele: LGB RMSE floor:\",np.sqrt(metrics.mean_squared_error(train_y2, np.floor(pre_train2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict(xgb_model2,test_x2,\"xgb\", 20181004)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合xgb-lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_lgb=pd.read_csv(\"result/lgb_result_20181004.csv\")\n",
    "pd_xgb=pd.read_csv(\"result/xgb_result_20181004.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_out=pd_lgb.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_out['car_number']=np.ceil((pd_xgb['car_number']+pd_lgb['car_number'])/2)\n",
    "pd_out.to_csv(\"result/merge_lgb_xgb_mean_20181004_ceil.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_out['car_number']=np.floor((pd_xgb['car_number']+pd_lgb['car_number'])/2)\n",
    "pd_out.to_csv(\"result/merge_lgb_xgb_mean_20181004_floor.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
